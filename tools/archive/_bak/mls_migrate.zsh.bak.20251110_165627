#!/usr/bin/env zsh
set -euo pipefail

# mls_migrate.zsh â€” migrate old lessons (g/knowledge/mls_lessons.jsonl) â†’ new ledger (mls/ledger/YYYY-MM-DD.jsonl)
# Usage:
#   tools/mls_migrate.zsh --dry-run
#   tools/mls_migrate.zsh --run
# Notes:
# - Keeps old file untouched (read-only).
# - Splits by date derived from .ts/.timestamp (string ISO) or uses today if missing.
# - Preserves: related_session â†’ source.session, related_wo â†’ links.wo_id
# - Adds: memo (rich context), source.producer="clc" (default), confidence=0.8 (default)

BASE="${BASE:-$HOME/02luka}"
OLD="$BASE/g/knowledge/mls_lessons.jsonl"
LEDGER_DIR="$BASE/mls/ledger"
REPORT="$BASE/g/reports/mls/migration_report.txt"
MODE="${1:---dry-run}"

[[ -f "$OLD" ]] || { echo "âŒ Old lessons not found: $OLD"; exit 1; }
mkdir -p "$LEDGER_DIR" "$(dirname "$REPORT")"

count_total=0
count_ok=0
count_skipped=0

# Helper: derive day (YYYY-MM-DD) from ts string (prefer first 10 chars if ISO-like)
derive_day() {
  local ts="$1"
  if [[ -n "$ts" && "$ts" == 20??-* ]]; then
    echo "${ts:0:10}"
  else
    date +%Y-%m-%d
  fi
}

echo "â–¶ï¸ Migration mode: $MODE" > "$REPORT"
echo "Source: $OLD" >> "$REPORT"
echo "Started: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> "$REPORT"
echo "---" >> "$REPORT"

while IFS= read -r line || [[ -n "$line" ]]; do
  [[ -z "$line" ]] && continue
  if ! echo "$line" | jq -e . >/dev/null 2>&1; then
    ((count_skipped++))
    echo "skip: not json" >> "$REPORT"
    continue
  fi
  ((count_total++))

  # Extract fields with fallbacks
  ts="$(echo "$line" | jq -r '(.ts // .timestamp // "")')"
  [[ "$ts" == "null" ]] && ts=""
  [[ -z "$ts" ]] && ts="$(date -u +%Y-%m-%dT%H:%M:%SZ)"
  day="$(derive_day "$ts")"

  new_json="$(echo "$line" | jq -c --arg ts "$ts" '
    {
      ts: $ts,
      type: (.type // "improvement"),
      title: (.title // "Untitled"),
      summary: (.summary // .description // "â€”"),
      memo: (.context // .memo // empty),
      source: {
        producer: ("clc"),
        context: (.context_enum // .context // "local"),
        repo: (.repo // empty),
        run_id: (.run_id // empty),
        workflow: (.workflow // empty),
        sha: (.sha // empty),
        artifact: (.artifact // empty),
        artifact_path: (.artifact_path // empty),
        session: (.related_session // .session // empty)
      },
      links: {
        followup_id: (.followup_id // empty),
        wo_id: (
          if (.related_wo? and (.related_wo|type=="string")) then
            (.related_wo | capture("(?<id>[A-Za-z0-9_-]+)$").id ) # extract tail id
          else
            (.wo_id // empty)
          end
        )
      },
      tags: (.tags // []),
      author: (.author // "clc"),
      confidence: ((.confidence // 0.8) | tonumber)
    }'
  )"

  if [[ "$MODE" == "--dry-run" ]]; then
    # validate shape quickly
    echo "$new_json" | jq -e '.ts and .type and .title and .summary and .source' >/dev/null || {
      ((count_skipped++))
      echo "skip: schema-lite fail @ $ts" >> "$REPORT"
      continue
    }
    ((count_ok++))
    echo "ok(dry): $day" >> "$REPORT"
  else
    # append to daily ledger (append-only)
    out="$LEDGER_DIR/$day.jsonl"
    printf '%s\n' "$new_json" >> "$out"
    ((count_ok++))
    echo "ok(write): $out" >> "$REPORT"
  fi
done < "$OLD"

echo "---" >> "$REPORT"
echo "Total: $count_total, OK: $count_ok, Skipped: $count_skipped" >> "$REPORT"
echo "Finished: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> "$REPORT"
echo "ðŸ“„ Report â†’ $REPORT"
